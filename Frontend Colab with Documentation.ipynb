{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZZqWZ9ZOhi2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOJ_6HQbOipd"
      },
      "source": [
        "# Interactive QA Bot Documentation\n",
        "\n",
        "This documentation will guide you through using the interactive QA bot application built with Streamlit. The application allows you to upload documents, interact with a chatbot, and view responses based on the content of the uploaded document.\n",
        "\n",
        "## Uploading Files\n",
        "\n",
        "1. **File Uploader**\n",
        "\n",
        "    - **Interface**: The file uploader is located in the center of the application interface.\n",
        "    - **Supported Formats**: You can upload documents in TXT or PDF format.\n",
        "\n",
        "    ```python\n",
        "    uploaded_file = st.file_uploader(\"Upload your document (TXT or PDF only)\", type=[\"txt\", \"pdf\"], help=\"Drag and drop file here or click to browse.\")\n",
        "    ```\n",
        "\n",
        "    - **Action**: Drag and drop your file into the uploader area or click to browse for the file.\n",
        "\n",
        "2. **Processing the Uploaded File**\n",
        "\n",
        "    - **Temporary Storage**: The uploaded file is saved temporarily on the server.\n",
        "\n",
        "    ```python\n",
        "    temp_file_path = save_uploaded_file(uploaded_file)\n",
        "    ```\n",
        "\n",
        "    - **Initialization**: The QA bot is initialized with the path of the uploaded file.\n",
        "\n",
        "    ```python\n",
        "    chatbot = QAChatbot(temp_file_path)\n",
        "    ```\n",
        "\n",
        "    - **Success Message**: A success message will be shown once the file is uploaded and the bot is ready to use.\n",
        "\n",
        "    ```python\n",
        "    st.success(\"File uploaded successfully! You can now chat with the bot.\")\n",
        "    ```\n",
        "\n",
        "## Interacting with the Bot\n",
        "\n",
        "1. **Chat History Display**\n",
        "\n",
        "    - **View Previous Messages**: The chat history displays previous interactions with the bot.\n",
        "\n",
        "    ```python\n",
        "    for message in st.session_state['messages']:\n",
        "        if message['role'] == 'user':\n",
        "            st.markdown(f'<div style=\"background-color: #e1ffc7; color: #000; border-radius: 10px; padding: 10px; margin-bottom: 5px;\"><strong>You:</strong> {message[\"content\"]}</div>', unsafe_allow_html=True)\n",
        "        else:\n",
        "            st.markdown(f'<div style=\"background-color: #dbe6f4; color: #000; border-radius: 10px; padding: 10px; margin-bottom: 5px;\"><strong>Bot:</strong> {message[\"content\"]}</div>', unsafe_allow_html=True)\n",
        "            if 'segments' in message:\n",
        "                st.markdown('<div style=\"background-color: #f4f4f4; color: #000; border-radius: 10px; padding: 10px; margin-top: 5px;\"><strong>Retrieved Segments:</strong></div>', unsafe_allow_html=True)\n",
        "                for segment in message['segments']:\n",
        "                    st.markdown(f'<div style=\"background-color: #f9f9f9; color: #000; border-radius: 5px; padding: 5px; margin-bottom: 3px;\">- {segment}</div>', unsafe_allow_html=True)\n",
        "    ```\n",
        "\n",
        "    - **User Messages**: Displayed with a light green background.\n",
        "    - **Bot Responses**: Displayed with a light blue background.\n",
        "    - **Retrieved Segments**: If applicable, shows the segments of the document used to generate the bot's response.\n",
        "\n",
        "2. **Sending a Query**\n",
        "\n",
        "    - **Input Form**: Type your query into the text input field and submit it.\n",
        "\n",
        "    ```python\n",
        "    with st.form(key='input_form', clear_on_submit=True):\n",
        "        user_query = st.text_input(\"Type your message:\", key=\"user_input_form\")\n",
        "        submit_button = st.form_submit_button(\"Send\")\n",
        "    ```\n",
        "\n",
        "    - **Submit Query**: When you submit a query, it is added to the chat history, and the bot processes the query.\n",
        "\n",
        "    ```python\n",
        "    if submit_button and user_query:\n",
        "        # Store the user query in chat history\n",
        "        st.session_state['messages'].append({'role': 'user', 'content': user_query})\n",
        "\n",
        "        # Get the response from the chatbot\n",
        "        response, retrieved_segments = chatbot.interact_with_llm(user_query)\n",
        "\n",
        "        # Store the bot's response and retrieved segments in chat history\n",
        "        st.session_state['messages'].append({'role': 'bot', 'content': response, 'segments': retrieved_segments})\n",
        "\n",
        "        # Rerun the app to update the chat history\n",
        "        st.experimental_rerun()\n",
        "    ```\n",
        "\n",
        "    - **Response Handling**: The bot's response and the relevant document segments are displayed in the chat history.\n",
        "\n",
        "## No File Uploaded\n",
        "\n",
        "- **Warning Message**: If no file is uploaded, a warning message will prompt you to upload a TXT or PDF file to start interacting with the bot.\n",
        "\n",
        "    ```python\n",
        "    else:\n",
        "        st.warning(\"Please upload a TXT or PDF file to start.\")\n",
        "    ```\n",
        "\n",
        "This documentation should help users understand how to interact with the QA bot application, upload files, and view the responses effectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "Tej_l63xG_HN",
        "outputId": "400ba060-b4db-40c5-ae41-c758f343d916"
      },
      "outputs": [],
      "source": [
        "%pip install streamlit\n",
        "%pip install llama_index\n",
        "%pip install llama-index-vector-stores-chroma\n",
        "%pip install llama_index-embeddings-gemini\n",
        "%pip install llama-index-llms-gemini\n",
        "%pip install PyPDF2\n",
        "%pip install chromadb\n",
        "%pip install google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "OIT6FTXVEbJP"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "# Import the QAChatbot class from your backend\n",
        "from Backend import QAChatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_Eq6jdCIDWC"
      },
      "source": [
        "### Function to Save Uploaded File Temporarily\n",
        "\n",
        "This function is responsible for temporarily saving the file uploaded by the user. When a user uploads a document, the file needs to be processed by the backend, but first, it must be saved on the system. This function handles that by saving the uploaded file in a temporary location.\n",
        "\n",
        "1. **`uploadedfile`**: This is the file object passed when a user uploads a document (e.g., a `.txt` or `.pdf` file).\n",
        "2. **`tempfile.NamedTemporaryFile`**: This creates a temporary file in the system. The `delete=False` argument ensures that the file will not be deleted automatically when closed, and `suffix='.' + uploadedfile.name.split('.')[-1]` sets the file's extension (e.g., `.txt` or `.pdf`).\n",
        "3. **`uploadedfile.getbuffer()`**: Reads the file contents and stores them in a buffer so that it can be written to the temporary file.\n",
        "4. **Return**: The function returns the path to the saved temporary file so that it can be processed further by the QA chatbot.\n",
        "\n",
        "#### Why is this needed?\n",
        "The file is saved temporarily so that it can be safely processed by the backend. This method ensures that the file is isolated in a temporary directory and won't interfere with other files, while also giving flexibility to handle different file types.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2ZHIwZvCGuNY"
      },
      "outputs": [],
      "source": [
        "# Function to save uploaded file temporarily\n",
        "def save_uploaded_file(uploadedfile):\n",
        "    # Create a temporary file with the same extension as the uploaded file\n",
        "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.' + uploadedfile.name.split('.')[-1])\n",
        "\n",
        "    # Write the contents of the uploaded file into the temporary file\n",
        "    temp_file.write(uploadedfile.getbuffer())\n",
        "\n",
        "    # Return the path of the saved temporary file\n",
        "    return temp_file.name\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIZgqgxxImdb"
      },
      "source": [
        "### Initializing Session State and Setting Up the Streamlit App\n",
        "\n",
        "1. **Initialize Session State**\n",
        "\n",
        "    ```python\n",
        "    # Initialize session state to store chat history\n",
        "    if 'messages' not in st.session_state:\n",
        "        st.session_state['messages'] = []\n",
        "    ```\n",
        "\n",
        "    - **Purpose**: This code block initializes the session state to store the chat history.\n",
        "    - **`st.session_state`**: A special dictionary-like object provided by Streamlit to store data across different user interactions and app reruns.\n",
        "    - **`'messages'`**: A key used to store the chat history. It is initialized as an empty list if it does not already exist in the session state. This list will keep track of all user and bot messages throughout the session.\n",
        "\n",
        "2. **Streamlit App Layout**\n",
        "\n",
        "    ```python\n",
        "    # Streamlit app layout\n",
        "    st.set_page_config(page_title=\"Chat-style QA Bot\", layout=\"wide\", page_icon=\"💬\")\n",
        "    ```\n",
        "\n",
        "    - **Purpose**: Configures the layout and appearance of the Streamlit app.\n",
        "    - **`st.set_page_config`**: A function that sets the title, layout, and icon for the app.\n",
        "      - **`page_title=\"Chat-style QA Bot\"`**: Sets the title of the web page that appears in the browser tab.\n",
        "      - **`layout=\"wide\"`**: Configures the app layout to be wide, making use of the full width of the screen for better display of content.\n",
        "      - **`page_icon=\"💬\"`**: Sets the icon shown in the browser tab to a chat bubble emoji.\n",
        "\n",
        "3. **App Header**\n",
        "\n",
        "    ```python\n",
        "    # App header\n",
        "    st.markdown(\"<h1 style='text-align: center; color: #FF4B4B;'>💬 Chat-style QA Bot</h1>\", unsafe_allow_html=True)\n",
        "    st.markdown(\"<h4 style='text-align: center;'>Upload your document and start chatting!</h4>\", unsafe_allow_html=True)\n",
        "    ```\n",
        "\n",
        "    - **Purpose**: Displays the header and subtitle of the app.\n",
        "    - **`st.markdown`**: Renders Markdown and HTML content.\n",
        "      - **`<h1>`**: Creates a main heading with a chat bubble emoji, centered and styled with a red color.\n",
        "      - **`<h4>`**: Adds a smaller heading below the main one, instructing users to upload a document and start chatting.\n",
        "      - **`unsafe_allow_html=True`**: Allows the use of raw HTML in Markdown, enabling custom styling and formatting.\n",
        "\n",
        "4. **File Uploader**\n",
        "\n",
        "    ```python\n",
        "    # File uploader\n",
        "    uploaded_file = st.file_uploader(\"Upload your document (TXT or PDF only)\", type=[\"txt\", \"pdf\"], help=\"Drag and drop file here or click to browse.\")\n",
        "    ```\n",
        "\n",
        "    - **Purpose**: Provides a file upload widget for users to upload documents.\n",
        "    - **`st.file_uploader`**: A Streamlit widget that allows users to upload files.\n",
        "      - **`\"Upload your document (TXT or PDF only)\"`**: The label displayed to users for the upload widget.\n",
        "      - **`type=[\"txt\", \"pdf\"]`**: Restricts the file types that can be uploaded to text files (`.txt`) and PDF files (`.pdf`).\n",
        "      - **`help=\"Drag and drop file here or click to browse.\"`**: Provides additional guidance to users on how to upload a file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ToNBZZcFHiEW",
        "outputId": "b7cf20a8-e886-471c-eaa7-04a283d29cd9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-18 12:32:46.265 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-18 12:32:46.268 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
            "2024-09-18 12:32:46.270 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-18 12:32:46.272 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-18 12:32:46.345 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-18 12:32:46.346 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-18 12:32:46.516 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2024-09-18 12:32:46.517 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-18 12:32:46.520 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-18 12:32:46.524 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-18 12:32:46.526 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-18 12:32:46.528 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-18 12:32:46.529 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-18 12:32:46.531 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "# Initialize session state to store chat history\n",
        "if 'messages' not in st.session_state:\n",
        "    st.session_state['messages'] = []\n",
        "\n",
        "# Streamlit app layout\n",
        "st.set_page_config(page_title=\"Chat-style QA Bot\", layout=\"wide\", page_icon=\"💬\")\n",
        "\n",
        "# App header\n",
        "st.markdown(\"<h1 style='text-align: center; color: #FF4B4B;'>💬 Chat-style QA Bot</h1>\", unsafe_allow_html=True)\n",
        "st.markdown(\"<h4 style='text-align: center;'>Upload your document and start chatting!</h4>\", unsafe_allow_html=True)\n",
        "\n",
        "# File uploader\n",
        "uploaded_file = st.file_uploader(\"Upload your document (TXT or PDF only)\", type=[\"txt\", \"pdf\"], help=\"Drag and drop file here or click to browse.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPpMt_dmJJfB"
      },
      "source": [
        "### Handling Uploaded Files and Chat Interactions\n",
        "\n",
        "1. **Check if a File is Uploaded**\n",
        "\n",
        "    ```python\n",
        "    if uploaded_file is not None:\n",
        "    ```\n",
        "\n",
        "    - **Purpose**: This condition checks if a file has been uploaded by the user.\n",
        "    - **`uploaded_file`**: Contains the file object if a file is uploaded, otherwise it is `None`.\n",
        "\n",
        "2. **Save the Uploaded File Temporarily**\n",
        "\n",
        "    ```python\n",
        "    # Save the uploaded file temporarily\n",
        "    temp_file_path = save_uploaded_file(uploaded_file)\n",
        "    ```\n",
        "\n",
        "    - **Purpose**: Calls the `save_uploaded_file` function to save the uploaded file to a temporary location.\n",
        "    - **`temp_file_path`**: Stores the path to the temporarily saved file, which is used for further processing by the QA bot.\n",
        "\n",
        "3. **Initialize the QA Bot**\n",
        "\n",
        "    ```python\n",
        "    # Initialize the QA bot with the document path\n",
        "    chatbot = QAChatbot(temp_file_path)\n",
        "    ```\n",
        "\n",
        "    - **Purpose**: Creates an instance of the `QAChatbot` class, passing the path of the temporary file to it.\n",
        "    - **`chatbot`**: An object of `QAChatbot` that will interact with the uploaded document and process queries.\n",
        "\n",
        "4. **Show Success Message**\n",
        "\n",
        "    ```python\n",
        "    st.success(\"File uploaded successfully! You can now chat with the bot.\")\n",
        "    ```\n",
        "\n",
        "    - **Purpose**: Displays a success message to the user indicating that the file has been uploaded and the chat functionality is now available.\n",
        "\n",
        "5. **Display Chat History**\n",
        "\n",
        "    ```python\n",
        "    # Display chat\n",
        "    st.markdown(\"### Chat History\")\n",
        "    ```\n",
        "\n",
        "    - **Purpose**: Adds a heading to the page to display the chat history.\n",
        "\n",
        "6. **Render Chat History**\n",
        "\n",
        "    ```python\n",
        "    # Chat history display\n",
        "    for message in st.session_state['messages']:\n",
        "        if message['role'] == 'user':\n",
        "            st.markdown(f'<div style=\"background-color: #e1ffc7; color: #000; border-radius: 10px; padding: 10px; margin-bottom: 5px;\"><strong>You:</strong> {message[\"content\"]}</div>', unsafe_allow_html=True)\n",
        "        else:\n",
        "            st.markdown(f'<div style=\"background-color: #dbe6f4; color: #000; border-radius: 10px; padding: 10px; margin-bottom: 5px;\"><strong>Bot:</strong> {message[\"content\"]}</div>', unsafe_allow_html=True)\n",
        "            if 'segments' in message:\n",
        "                st.markdown('<div style=\"background-color: #f4f4f4; color: #000; border-radius: 10px; padding: 10px; margin-top: 5px;\"><strong>Retrieved Segments:</strong></div>', unsafe_allow_html=True)\n",
        "                for segment in message['segments']:\n",
        "                    st.markdown(f'<div style=\"background-color: #f9f9f9; color: #000; border-radius: 5px; padding: 5px; margin-bottom: 3px;\">- {segment}</div>', unsafe_allow_html=True)\n",
        "    ```\n",
        "\n",
        "    - **Purpose**: Loops through the chat history stored in `st.session_state['messages']` and renders each message on the page.\n",
        "    - **User Messages**: Displayed with a light green background.\n",
        "    - **Bot Responses**: Displayed with a light blue background.\n",
        "    - **Retrieved Segments**: If available, shows segments from the document that were used to generate the bot's response.\n",
        "\n",
        "7. **User Input for Chat**\n",
        "\n",
        "    ```python\n",
        "    # User input for chat\n",
        "    with st.form(key='input_form', clear_on_submit=True):\n",
        "        user_query = st.text_input(\"Type your message:\", key=\"user_input_form\")\n",
        "        submit_button = st.form_submit_button(\"Send\")\n",
        "    ```\n",
        "\n",
        "    - **Purpose**: Provides a form for the user to type and submit their query.\n",
        "    - **`st.form`**: Creates a form with a key to manage state and clear input upon submission.\n",
        "    - **`st.text_input`**: A text input field for the user to type their message.\n",
        "    - **`st.form_submit_button`**: A button to submit the form and send the query to the bot.\n",
        "\n",
        "8. **Handle Form Submission**\n",
        "\n",
        "    ```python\n",
        "    if submit_button and user_query:\n",
        "        # Store the user query in chat history\n",
        "        st.session_state['messages'].append({'role': 'user', 'content': user_query})\n",
        "\n",
        "        # Get the response from the chatbot\n",
        "        response, retrieved_segments = chatbot.interact_with_llm(user_query)\n",
        "\n",
        "        # Store the bot's response and retrieved segments in chat history\n",
        "        st.session_state['messages'].append({'role': 'bot', 'content': response, 'segments': retrieved_segments})\n",
        "\n",
        "        # Rerun the app to update the chat history\n",
        "        st.experimental_rerun()\n",
        "    ```\n",
        "\n",
        "    - **Purpose**: Processes the user query when the form is submitted.\n",
        "    - **Check Submission**: Verifies if the submit button was clicked and if the user query is not empty.\n",
        "    - **Store Query**: Adds the user's query to the chat history.\n",
        "    - **Get Response**: Calls the `interact_with_llm` method of the `chatbot` to get a response and the segments used.\n",
        "    - **Store Response**: Adds the bot's response and segments to the chat history.\n",
        "    - **Update UI**: Uses `st.experimental_rerun()` to refresh the app and display the updated chat history.\n",
        "\n",
        "9. **Display Warning if No File is Uploaded**\n",
        "\n",
        "    ```python\n",
        "    else:\n",
        "        st.warning(\"Please upload a TXT or PDF file to start.\")\n",
        "    ```\n",
        "\n",
        "    - **Purpose**: Displays a warning message if no file has been uploaded, prompting the user to upload a file to interact with the bot.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RsBL1YF-HmIr",
        "outputId": "a7949d8e-e514-4910-8425-52be349b3d56"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-18 12:32:50.175 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-18 12:32:50.183 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "if uploaded_file is not None:\n",
        "    # Save the uploaded file temporarily\n",
        "    temp_file_path = save_uploaded_file(uploaded_file)\n",
        "\n",
        "    # Initialize the QA bot with the document path\n",
        "    chatbot = QAChatbot(temp_file_path)\n",
        "\n",
        "    st.success(\"File uploaded successfully! You can now chat with the bot.\")\n",
        "\n",
        "    # Display chat\n",
        "    st.markdown(\"### Chat History\")\n",
        "\n",
        "    # Chat history display\n",
        "    for message in st.session_state['messages']:\n",
        "        if message['role'] == 'user':\n",
        "            st.markdown(f'<div style=\"background-color: #e1ffc7; color: #000; border-radius: 10px; padding: 10px; margin-bottom: 5px;\"><strong>You:</strong> {message[\"content\"]}</div>', unsafe_allow_html=True)\n",
        "        else:\n",
        "            st.markdown(f'<div style=\"background-color: #dbe6f4; color: #000; border-radius: 10px; padding: 10px; margin-bottom: 5px;\"><strong>Bot:</strong> {message[\"content\"]}</div>', unsafe_allow_html=True)\n",
        "            if 'segments' in message:\n",
        "                st.markdown('<div style=\"background-color: #f4f4f4; color: #000; border-radius: 10px; padding: 10px; margin-top: 5px;\"><strong>Retrieved Segments:</strong></div>', unsafe_allow_html=True)\n",
        "                for segment in message['segments']:\n",
        "                    st.markdown(f'<div style=\"background-color: #f9f9f9; color: #000; border-radius: 5px; padding: 5px; margin-bottom: 3px;\">- {segment}</div>', unsafe_allow_html=True)\n",
        "\n",
        "    # User input for chat\n",
        "    with st.form(key='input_form', clear_on_submit=True):\n",
        "        user_query = st.text_input(\"Type your message:\", key=\"user_input_form\")\n",
        "        submit_button = st.form_submit_button(\"Send\")\n",
        "\n",
        "        if submit_button and user_query:\n",
        "            # Store the user query in chat history\n",
        "            st.session_state['messages'].append({'role': 'user', 'content': user_query})\n",
        "\n",
        "            # Get the response from the chatbot\n",
        "            response, retrieved_segments = chatbot.interact_with_llm(user_query)\n",
        "\n",
        "            # Store the bot's response and retrieved segments in chat history\n",
        "            st.session_state['messages'].append({'role': 'bot', 'content': response, 'segments': retrieved_segments})\n",
        "\n",
        "            # Rerun the app to update the chat history\n",
        "            st.experimental_rerun()\n",
        "\n",
        "else:\n",
        "    st.warning(\"Please upload a TXT or PDF file to start.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Challenges faced, and solutions\n",
        "---\n",
        "\n",
        "## Key Decisions and Design\n",
        "\n",
        "### 1. **Choosing Streamlit for the Frontend**\n",
        "- **Decision**: I selected **Streamlit** for the frontend to create a simple and interactive web-based user interface (UI).\n",
        "- **Reason**: Streamlit is lightweight, easy to use, and excellent for quickly deploying AI-based applications with minimal configuration.\n",
        "- **Challenge**: Integrating a smooth chat-based interface with real-time interaction and file upload functionality.\n",
        "- **Solution**: Streamlit’s form-based interaction allowed for smooth handling of user inputs and dynamic UI updates. I utilized session state to manage chat history across interactions.\n",
        "\n",
        "### 2. **Managing File Uploads**\n",
        "- **Decision**: I implemented a file uploader component to allow users to upload PDF or TXT files.\n",
        "- **Reason**: The chatbot needed to process documents, so an easy-to-use file upload mechanism was essential.\n",
        "- **Challenge**: Handling uploaded files properly in a temporary environment and limiting supported file types.\n",
        "- **Solution**: Using `st.file_uploader`, I limited file types and used the `tempfile` module for temporary file storage.\n",
        "\n",
        "### 3. **Storing and Displaying Chat History**\n",
        "- **Decision**: I used `Streamlit’s session state` to store conversation history, maintaining chat continuity between queries.\n",
        "- **Reason**: Users should see previous interactions, and the bot should retain context throughout the conversation.\n",
        "- **Challenge**: Ensuring the chat history persists across interactions while keeping a clean UI.\n",
        "- **Solution**: `st.session_state` stored messages with roles (user/bot). Markdown formatting was used for a clean and interactive display of chat history.\n",
        "\n",
        "### 4. **Interactive Chat Interface**\n",
        "- **Decision**: Designed the chat interface to visually distinguish between user inputs, bot responses, and document segments.\n",
        "- **Reason**: A clear, visually engaging chat interface improves usability and engagement.\n",
        "- **Challenge**: Formatting dynamic chat history while keeping document segments separate.\n",
        "- **Solution**: Applied different colors for user (`#e1ffc7`) and bot (`#dbe6f4`) messages using HTML/CSS via Markdown.\n",
        "\n",
        "### 5. **Form for User Input**\n",
        "- **Decision**: Used `st.form` to handle user input for controlled submission of chat updates.\n",
        "- **Reason**: A form allows controlled submission, easier validation, and state management.\n",
        "- **Challenge**: Ensuring responsive, real-time chat input processing.\n",
        "- **Solution**: `st.form_submit_button` efficiently handled user input and triggered backend processing, updating chat history dynamically.\n",
        "\n",
        "### 6. **Handling Empty States**\n",
        "- **Decision**: Added a warning message when no file was uploaded to guide users.\n",
        "- **Reason**: Providing clear instructions enhances the user experience.\n",
        "- **Challenge**: Preventing user interaction without necessary inputs and providing feedback.\n",
        "- **Solution**: Displayed `st.warning` when no file was uploaded, with additional instructions in the `help` parameter.\n",
        "\n",
        "---\n",
        "\n",
        "## Challenges and Solutions\n",
        "\n",
        "### 1. **Maintaining Chat Continuity**\n",
        "- **Challenge**: Streamlit resets state after each interaction, making conversation history tricky to maintain.\n",
        "- **Solution**: Utilized `st.session_state` to store and update the chat history with each interaction.\n",
        "\n",
        "### 2. **Displaying Document Segments**\n",
        "- **Challenge**: Displaying both bot responses and retrieved document segments without cluttering the interface.\n",
        "- **Solution**: Designed a visually distinct section for document segments, maintaining clarity in the chat interface.\n",
        "\n",
        "### 3. **Responsive Layout**\n",
        "- **Challenge**: Ensuring the layout adapts to different screen sizes, especially smaller screens.\n",
        "- **Solution**: Used `st.set_page_config` to set the layout to `wide`, optimizing for different devices.\n",
        "\n",
        "### 4. **Handling Temporary Files**\n",
        "- **Challenge**: Managing uploaded files efficiently in a temporary environment.\n",
        "- **Solution**: Leveraged Python’s `tempfile` module to store files temporarily during the session.\n",
        "\n",
        "### 5. **Ensuring Clear User Feedback**\n",
        "- **Challenge**: Providing clear feedback on user actions (file upload, queries) to enhance user experience.\n",
        "- **Solution**: Added success and warning messages using `st.success` and `st.warning` to guide users.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Components\n",
        "\n",
        "### 1. **File Upload Handling**\n",
        "- The `save_uploaded_file()` function saves the uploaded document temporarily for backend processing.\n",
        "\n",
        "### 2. **Session State for Chat History**\n",
        "- Chat history is maintained in `st.session_state`, ensuring continuity across interactions.\n",
        "\n",
        "### 3. **User Input via Form**\n",
        "- User input is managed via a form, ensuring controlled and validated submission of queries.\n",
        "\n",
        "### 4. **Dynamic Chat Rendering**\n",
        "- Chat history is rendered using Markdown, providing a clean, interactive display for both user and bot messages.\n",
        "\n",
        "### 5. **Real-Time Interaction**\n",
        "- The backend’s `interact_with_llm()` method processes user queries in real time, updating chat history dynamically.\n",
        "\n",
        "---\n",
        "\n",
        "This explanation outlines the major design decisions, challenges, and solutions implemented in the `app.py` code, ensuring a smooth and user-friendly chatbot experience through Streamlit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Key Decisions and Design\n",
        "\n",
        "### 1. **Choosing Streamlit for the Frontend**\n",
        "- **Decision**: I selected **Streamlit** for the frontend to create a simple and interactive web-based user interface (UI).\n",
        "- **Reason**: Streamlit is lightweight, easy to use, and excellent for quickly deploying AI-based applications with minimal configuration.\n",
        "- **Challenge**: Integrating a smooth chat-based interface with real-time interaction and file upload functionality.\n",
        "- **Solution**: Streamlit’s form-based interaction allowed for smooth handling of user inputs and dynamic UI updates. I utilized session state to manage chat history across interactions.\n",
        "\n",
        "### 2. **Managing File Uploads**\n",
        "- **Decision**: I implemented a file uploader component to allow users to upload PDF or TXT files.\n",
        "- **Reason**: The chatbot needed to process documents, so an easy-to-use file upload mechanism was essential.\n",
        "- **Challenge**: Handling uploaded files properly in a temporary environment and limiting supported file types.\n",
        "- **Solution**: Using `st.file_uploader`, I limited file types and used the `tempfile` module for temporary file storage.\n",
        "\n",
        "### 3. **Storing and Displaying Chat History**\n",
        "- **Decision**: I used `Streamlit’s session state` to store conversation history, maintaining chat continuity between queries.\n",
        "- **Reason**: Users should see previous interactions, and the bot should retain context throughout the conversation.\n",
        "- **Challenge**: Ensuring the chat history persists across interactions while keeping a clean UI.\n",
        "- **Solution**: `st.session_state` stored messages with roles (user/bot). Markdown formatting was used for a clean and interactive display of chat history.\n",
        "\n",
        "### 4. **Interactive Chat Interface**\n",
        "- **Decision**: Designed the chat interface to visually distinguish between user inputs, bot responses, and document segments.\n",
        "- **Reason**: A clear, visually engaging chat interface improves usability and engagement.\n",
        "- **Challenge**: Formatting dynamic chat history while keeping document segments separate.\n",
        "- **Solution**: Applied different colors for user (`#e1ffc7`) and bot (`#dbe6f4`) messages using HTML/CSS via Markdown.\n",
        "\n",
        "### 5. **Form for User Input**\n",
        "- **Decision**: Used `st.form` to handle user input for controlled submission of chat updates.\n",
        "- **Reason**: A form allows controlled submission, easier validation, and state management.\n",
        "- **Challenge**: Ensuring responsive, real-time chat input processing.\n",
        "- **Solution**: `st.form_submit_button` efficiently handled user input and triggered backend processing, updating chat history dynamically.\n",
        "\n",
        "### 6. **Handling Empty States**\n",
        "- **Decision**: Added a warning message when no file was uploaded to guide users.\n",
        "- **Reason**: Providing clear instructions enhances the user experience.\n",
        "- **Challenge**: Preventing user interaction without necessary inputs and providing feedback.\n",
        "- **Solution**: Displayed `st.warning` when no file was uploaded, with additional instructions in the `help` parameter.\n",
        "\n",
        "---\n",
        "\n",
        "## Challenges and Solutions\n",
        "\n",
        "### 1. **Maintaining Chat Continuity**\n",
        "- **Challenge**: Streamlit resets state after each interaction, making conversation history tricky to maintain.\n",
        "- **Solution**: Utilized `st.session_state` to store and update the chat history with each interaction.\n",
        "\n",
        "### 2. **Displaying Document Segments**\n",
        "- **Challenge**: Displaying both bot responses and retrieved document segments without cluttering the interface.\n",
        "- **Solution**: Designed a visually distinct section for document segments, maintaining clarity in the chat interface.\n",
        "\n",
        "### 3. **Responsive Layout**\n",
        "- **Challenge**: Ensuring the layout adapts to different screen sizes, especially smaller screens.\n",
        "- **Solution**: Used `st.set_page_config` to set the layout to `wide`, optimizing for different devices.\n",
        "\n",
        "### 4. **Handling Temporary Files**\n",
        "- **Challenge**: Managing uploaded files efficiently in a temporary environment.\n",
        "- **Solution**: Leveraged Python’s `tempfile` module to store files temporarily during the session.\n",
        "\n",
        "### 5. **Ensuring Clear User Feedback**\n",
        "- **Challenge**: Providing clear feedback on user actions (file upload, queries) to enhance user experience.\n",
        "- **Solution**: Added success and warning messages using `st.success` and `st.warning` to guide users.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Components\n",
        "\n",
        "### 1. **File Upload Handling**\n",
        "- The `save_uploaded_file()` function saves the uploaded document temporarily for backend processing.\n",
        "\n",
        "### 2. **Session State for Chat History**\n",
        "- Chat history is maintained in `st.session_state`, ensuring continuity across interactions.\n",
        "\n",
        "### 3. **User Input via Form**\n",
        "- User input is managed via a form, ensuring controlled and validated submission of queries.\n",
        "\n",
        "### 4. **Dynamic Chat Rendering**\n",
        "- Chat history is rendered using Markdown, providing a clean, interactive display for both user and bot messages.\n",
        "\n",
        "### 5. **Real-Time Interaction**\n",
        "- The backend’s `interact_with_llm()` method processes user queries in real time, updating chat history dynamically.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIAOS_qZOi-6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
